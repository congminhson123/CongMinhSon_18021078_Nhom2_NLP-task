{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vncorenlp import VnCoreNLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0                                                  1\n",
      "0     __CTXH__  Gần 500 học sinh phải học trong điều kiện tạm ...\n",
      "1     __CTXH__  Ngầm hóa các công trình hạ tầng kỹ thuật Theo ...\n",
      "2     __CTXH__  Những vấn đề mới trong tuyển sinh ĐH-CĐ 2006 P...\n",
      "3     __CTXH__  Chúng tôi nhìn thẳng sự thật để bước tới Có ha...\n",
      "4     __CTXH__  Đà Lạt: Xây dựng công viên 7,6 ha ở hạ lưu hồ ...\n",
      "...        ...                                                ...\n",
      "4995    __VH__  Ca sĩ trẻ Ngọc Khuê - Cô “Zin Zin” hiếu thảo C...\n",
      "4996    __VH__  Bình Minh: 'Tôi sợ kiểu sống thời thượng' \"Tôi...\n",
      "4997    __VH__  Phương Thanh không sai khi bênh Thu Phương Tôi...\n",
      "4998    __VH__  Kim Basinger - 50 tuổi vẫn muốn kết hôn Dù đã ...\n",
      "4999    __VH__  Đạo diễn Meirelles: 'Thành viên Viện Hàn lâm c...\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\acer\\Documents\\hoc tap\\KT LAB\\scikit-learn\\NLP task\\trainning.txt\", encoding = 'utf-8', delimiter = '\\t', header = None)\n",
    "test_data = pd.read_csv(r\"C:\\Users\\acer\\Documents\\hoc tap\\KT LAB\\scikit-learn\\NLP task\\testing.txt\", encoding = 'utf-8', delimiter = '\\t', header = None)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = VnCoreNLP(r\"C:\\Users\\acer\\Documents\\hoc tap\\KT LAB\\scikit-learn\\VnCoreNLP-master\\VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = [\"Labels\", \"Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Labels                                            Content\n",
      "0     __CTXH__  Gần 500 học sinh phải học trong điều kiện tạm ...\n",
      "1     __CTXH__  Ngầm hóa các công trình hạ tầng kỹ thuật Theo ...\n",
      "2     __CTXH__  Những vấn đề mới trong tuyển sinh ĐH-CĐ 2006 P...\n",
      "3     __CTXH__  Chúng tôi nhìn thẳng sự thật để bước tới Có ha...\n",
      "4     __CTXH__  Đà Lạt: Xây dựng công viên 7,6 ha ở hạ lưu hồ ...\n",
      "...        ...                                                ...\n",
      "4995    __VH__  Ca sĩ trẻ Ngọc Khuê - Cô “Zin Zin” hiếu thảo C...\n",
      "4996    __VH__  Bình Minh: 'Tôi sợ kiểu sống thời thượng' \"Tôi...\n",
      "4997    __VH__  Phương Thanh không sai khi bênh Thu Phương Tôi...\n",
      "4998    __VH__  Kim Basinger - 50 tuổi vẫn muốn kết hôn Dù đã ...\n",
      "4999    __VH__  Đạo diễn Meirelles: 'Thành viên Viện Hàn lâm c...\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.assign(TokenizedContent = [annotator.tokenize(x) for x in train_data['Content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Content</th>\n",
       "      <th>TokenizedContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__CTXH__</td>\n",
       "      <td>Gần 500 học sinh phải học trong điều kiện tạm ...</td>\n",
       "      <td>[[Gần, 500, học_sinh, phải, học, trong, điều_k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__CTXH__</td>\n",
       "      <td>Ngầm hóa các công trình hạ tầng kỹ thuật Theo ...</td>\n",
       "      <td>[[Ngầm, hoá, các, công_trình, hạ_tầng, kỹ_thuậ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__CTXH__</td>\n",
       "      <td>Những vấn đề mới trong tuyển sinh ĐH-CĐ 2006 P...</td>\n",
       "      <td>[[Những, vấn_đề, mới, trong, tuyển_sinh, ĐH-CĐ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__CTXH__</td>\n",
       "      <td>Chúng tôi nhìn thẳng sự thật để bước tới Có ha...</td>\n",
       "      <td>[[Chúng_tôi, nhìn, thẳng, sự_thật, để, bước, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Labels                                            Content  \\\n",
       "0  __CTXH__  Gần 500 học sinh phải học trong điều kiện tạm ...   \n",
       "1  __CTXH__  Ngầm hóa các công trình hạ tầng kỹ thuật Theo ...   \n",
       "2  __CTXH__  Những vấn đề mới trong tuyển sinh ĐH-CĐ 2006 P...   \n",
       "3  __CTXH__  Chúng tôi nhìn thẳng sự thật để bước tới Có ha...   \n",
       "\n",
       "                                    TokenizedContent  \n",
       "0  [[Gần, 500, học_sinh, phải, học, trong, điều_k...  \n",
       "1  [[Ngầm, hoá, các, công_trình, hạ_tầng, kỹ_thuậ...  \n",
       "2  [[Những, vấn_đề, mới, trong, tuyển_sinh, ĐH-CĐ...  \n",
       "3  [[Chúng_tôi, nhìn, thẳng, sự_thật, để, bước, t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gần', '500', 'học_sinh', 'phải', 'học', 'trong', 'điều_kiện', 'tạm_bợ', '(', 'NLĐ', ')', '-', 'Gần', '500', 'học_sinh', 'Trường', 'Tiểu_học', 'Đống_Đa', ',', 'P.', '25', ',', 'quận', 'Bình_Thạnh', '-', 'TPHCM', 'đến', 'nay', 'vẫn', 'phải', 'được', 'gởi', 'học', 'tạm', 'tại', '2', 'nơi', 'cách', 'nhà', 'khoảng', '5', 'km', 'do', 'ngôi', 'trường', 'này', 'đã', 'xuống_cấp', 'trầm_trọng', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_data['TokenizedContent'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = set(line.strip() for line in open('vietnamese-stopwords.txt',encoding=\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = []\n",
    "for paragraph in train_data['TokenizedContent']:\n",
    "    sentences = []\n",
    "    for sentence in paragraph:\n",
    "        words = []\n",
    "        for word in sentence:\n",
    "            if any(c.isdigit() for c in word):\n",
    "                words.append('0')\n",
    "                continue\n",
    "            if word not in stopword:\n",
    "                words.append(word)\n",
    "        sentences.append(words)\n",
    "    paragraphs.append(sentences)\n",
    "train_data['TokenizedContent'] = paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineWord = []\n",
    "for paragraph in train_data['TokenizedContent']:\n",
    "    merged = [' '.join(x) for x in paragraph]\n",
    "    combineWord.append(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineSentence = []\n",
    "for para in combineWord:\n",
    "    combineSentence.append(' '.join(para))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['TokenizedContent'] = combineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Labels                                            Content  \\\n",
      "0     __CTXH__  Gần 500 học sinh phải học trong điều kiện tạm ...   \n",
      "1     __CTXH__  Ngầm hóa các công trình hạ tầng kỹ thuật Theo ...   \n",
      "2     __CTXH__  Những vấn đề mới trong tuyển sinh ĐH-CĐ 2006 P...   \n",
      "3     __CTXH__  Chúng tôi nhìn thẳng sự thật để bước tới Có ha...   \n",
      "4     __CTXH__  Đà Lạt: Xây dựng công viên 7,6 ha ở hạ lưu hồ ...   \n",
      "...        ...                                                ...   \n",
      "4995    __VH__  Ca sĩ trẻ Ngọc Khuê - Cô “Zin Zin” hiếu thảo C...   \n",
      "4996    __VH__  Bình Minh: 'Tôi sợ kiểu sống thời thượng' \"Tôi...   \n",
      "4997    __VH__  Phương Thanh không sai khi bênh Thu Phương Tôi...   \n",
      "4998    __VH__  Kim Basinger - 50 tuổi vẫn muốn kết hôn Dù đã ...   \n",
      "4999    __VH__  Đạo diễn Meirelles: 'Thành viên Viện Hàn lâm c...   \n",
      "\n",
      "                                       TokenizedContent  \n",
      "0     Gần 0 học_sinh học điều_kiện tạm_bợ ( NLĐ ) - ...  \n",
      "1     Ngầm hoá công_trình hạ_tầng kỹ_thuật Theo , UB...  \n",
      "2     Những vấn_đề tuyển_sinh ĐH-CĐ 0 Phương_án tuyể...  \n",
      "3     Chúng_tôi thẳng sự_thật Có khác_biệt trình_độ ...  \n",
      "4     Đà_Lạt : Xây_dựng công_viên 0 ha hạ_lưu hồ Xuâ...  \n",
      "...                                                 ...  \n",
      "4995  Ca_sĩ trẻ Ngọc_Khuê - Cô “ Zin_Zin ” hiếu_thảo...  \n",
      "4996  Bình_Minh : ' Tôi sợ kiểu sống thời_thượng ' \"...  \n",
      "4997  Phương_Thanh sai bênh Thu_Phương_Tôi ủng_hộ Ph...  \n",
      "4998  Kim_Basinger - 0 kết_hôn Dù \" sống_dở_chết_dở ...  \n",
      "4999  Đạo_diễn Meirelles : ' Thành_viên Viện_Hàn_lâm...  \n",
      "\n",
      "[5000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gần 0 học_sinh học điều_kiện tạm_bợ ( NLĐ ) - Gần 0 học_sinh Trường Tiểu_học Đống_Đa , P. 0 , Bình_Thạnh - TPHCM gởi học tạm 0 0 km trường xuống_cấp trầm_trọng . Theo kế_hoạch , đầu năm_học 0 , Trường Tiểu_học Đống_Đa khởi_công xây_dựng chỗ học , , năm_học kết_thúc , xây trường . Nhiều phụ_huynh cảm_thấy yên_tâm hằng con_em học tình_trạng trường_lớp tạm_bợ đi_lại kém an_toàn như_thế .\n"
     ]
    }
   ],
   "source": [
    "print(train_data['TokenizedContent'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vec = TfidfVectorizer()\n",
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tfv = tf_vec.fit_transform(train_data['TokenizedContent'])\n",
    "X_cv = count_vec.fit_transform(train_data['TokenizedContent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = label.fit_transform(train_data['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 8, 8, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfv, X_test_tfv, y_train, y_test = train_test_split(\n",
    "    X_tfv, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 5, ..., 5, 6, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfv = X_train_tfv.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB.fit(X_train_tfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfv = X_test_tfv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_NB.predict(X_test_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 6 7 2 9 2 5 9 3 2 6 3 5 1 3 6 2 8 8 0 1 8 6 5 7 7 5 8 3 1 9 2 7 1 8 4\n",
      " 7 4 6 6 0 1 7 7 1 7 7 6 0 5 5 8 7 6 0 1 3 5 8 5 9 5 1 4 1 2 1 8 2 6 7 7 1\n",
      " 9 0 7 6 2 5 1 1 7 8 0 9 8 5 4 8 2 0 1 2 2 0 4 3 5 2 9 1 4 5 5 2 6 2 6 7 3\n",
      " 2 3 7 3 4 5 6 5 4 5 0 3 5 8 8 5 3 8 5 4 6 0 1 1 0 4 6 9 0 6 0 8 9 4 8 6 8\n",
      " 6 5 3 9 1 3 1 7 2 2 5 3 7 0 9 6 0 7 7 5 7 5 3 1 3 7 4 8 1 6 7 3 5 2 9 2 9\n",
      " 8 2 7 0 0 8 8 9 4 1 2 2 7 4 0 4 4 7 0 9 3 8 0 6 1 1 3 9 3 5 2 7 7 1 3 6 6\n",
      " 5 9 1 4 7 3 2 2 2 5 1 9 2 3 2 7 5 2 4 5 2 6 1 7 2 3 7 7 9 1 0 6 7 1 7 0 6\n",
      " 9 7 9 1 5 8 4 4 1 2 9 8 8 5 6 3 5 4 0 8 0 6 8 2 2 6 0 9 4 2 9 1 8 4 4 7 6\n",
      " 4 0 3 7 1 8 9 3 4 1 2 9 0 9 5 8 0 9 8 4 3 9 6 6 7 9 4 7 3 4 8 1 7 2 8 3 6\n",
      " 6 3 0 3 5 0 1 3 8 8 9 6 1 2 5 5 4 9 7 1 3 9 5 8 3 0 1 6 5 5 2 0 9 1 2 8 9\n",
      " 8 4 3 0 6 4 9 7 6 1 6 9 0 8 6 1 7 0 7 3 7 2 8 4 4 8 2 0 3 8 5 6 5 4 6 7 3\n",
      " 4 8 2 5 1 2 6 0 2 1 5 6 9 7 1 1 6 8 0 0 0 7 6 2 2 5 0 3 1 0 5 3 1 9 5 3 8\n",
      " 4 5 8 9 0 3 6 4 7 6 3 9 9 6 4 5 5 4 6 9 7 0 3 2 9 9 2 4 9 8 1 5 6 5 4 0 6\n",
      " 6 9 7 6 9 5 7 1 2 1 0 8 1 8 6 8 0 3 5 8 1 6 6 4 0 1 7 8 0 2 8 1 6 8 4 3 2\n",
      " 2 5 7 4 2 9 9 7 4 3 2 7 0 4 2 2 3 6 3 9 3 9 4 6 6 3 8 4 9 2 8 5 2 7 3 5 9\n",
      " 5 0 7 2 3 0 8 6 7 2 8 5 3 9 3 3 8 4 8 4 1 7 4 0 7 1 2 3 3 1 9 3 6 2 0 4 2\n",
      " 3 0 4 0 1 7 1 0 2 2 8 5 5 5 3 0 6 8 1 6 8 8 6 5 9 5 2 8 0 4 9 5 7 4 0 1 1\n",
      " 6 9 5 2 4 1 4 8 1 9 9 9 4 3 5 3 9 9 1 2 9 9 2 9 4 3 2 0 9 0 6 5 7 9 4 2 4\n",
      " 0 2 0 2 2 6 8 2 6 4 6 2 3 4 2 1 0 2 7 2 4 5 3 9 4 4 5 3 5 2 5 8 6 1 0 4 4\n",
      " 8 4 7 1 4 6 0 8 1 7 0 3 9 1 4 2 5 5 5 9 7 9 1 2 7 1 9 2 8 2 2 2 7 8 8 2 5\n",
      " 5 7 8 1 5 8 7 1 2 2 9 5 2 7 1 5 3 7 3 7 5 7 5 6 6 8 5 4 4 9 6 9 0 6 5 4 1\n",
      " 0 4 1 1 4 9 8 2 0 0 0 4 4 7 5 8 4 9 1 1 8 0 2 4 0 3 6 9 6 5 1 0 7 7 5 3 2\n",
      " 5 8 2 1 1 0 6 6 3 7 1 9 3 8 2 3 3 6 2 5 4 4 2 6 8 3 9 0 9 6 6 8 6 9 2 6 7\n",
      " 1 1 9 1 8 6 3 1 6 6 0 9 0 8 4 5 8 6 3 0 3 6 5 8 1 2 7 3 4 5 2 5 8 6 3 0 9\n",
      " 0 1 3 3 5 4 5 5 4 7 8 6 2 0 0 7 9 4 2 2 3 4 4 9 9 8 3 0 6 8 3 5 2 2 7 1 0\n",
      " 0 0 8 0 1 4 7 0 1 7 3 8 6 4 6 7 9 6 8 9 7 6 3 3 8 6 7 0 9 9 1 0 3 3 8 0 8\n",
      " 6 8 8 3 0 5 2 2 8 6 7 6 3 4 5 6 0 9 8 3 9 5 4 5 7 9 4 8 5 9 2 3 1 7 7 3 2\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# đánh giá phân lớp với tf-idf vectorizer và multinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044397327685632"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9015014339726914"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9012696293020616"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv, y_train, y_test = train_test_split(\n",
    "    X_cv, Y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_cv = X_train_cv.toarray()\n",
    "X_test_cv = X_test_cv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_NB.fit(X_train_cv, y_train)\n",
    "y_pred = clf_NB.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# đánh giá phân lớp với count vectorizer và multinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824641020399984"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777863305393803"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769999999999999"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8787203939798334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
